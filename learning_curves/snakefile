NUM_MODELS = 10
model_serials = [i for i in range(NUM_MODELS)]
INSTANCES = [i for i in range(100, 1100, 100)]
STEPS = [1200, 600, 300]


rule gather_stats:
#echo "gpu?"; read core; export CUDA_VISIBLE_DEVICES=$core;echo "batch?"; read batch; snakemake -j 12 --use-conda -k --batch gather_stats="$batch"
# snakemake -j 12 --use-conda gather_stats --batch gather_stats=2/4
    input:
        expand("models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_stats.jsonl",
        instances=INSTANCES,
        serial=model_serials,
        steps = STEPS,
        ) + expand("models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_stats.jsonl",
        instances=[10442],
        serial=[i for i in range(10)],
        steps = [6540],)
    output: "model_scores.png", "../paper_images/learning_curves.pdf"
    conda: "transformers"
    script: "scripts/plot_learning_curves.py"

rule calculate_stats:
    input: "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_postprocessedpredictions.jsonl"
    output: "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_stats.jsonl"
    conda: "transformers"
    params:
        modes = ["raw", "pp"],
        provenances = ["PS-HR", "MP", "SLO", "PS-RS"]
    script: "scripts/calculate_stats.py"

rule postprocess_predictions:
    input:
        predictions = "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_predictions.jsonl",
        datafiles=["../data_MP.jsonl", "../data_PS-HR.jsonl", "../data_SLO.jsonl", "../data_PS-RS.jsonl"]
    output: "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_postprocessedpredictions.jsonl"
    conda: "transformers"
    script: "scripts/postprocess_predictions.py"

rule concatenate_inferences:
    input: expand("models/model_{{instances}}_{{steps}}_{{serial}}/checkpoint-{{steps}}_predictions_{what}.jsonl", what="MP PS_HR SLO PS_RS".split())
    output: "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_predictions.jsonl"
    conda:"transformers"
    script:
        "scripts/concatenate_inferences.py"

rule run_inference_MP:
    input:
        checkpoint = "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}/",
        datafiles = ["../data_MP.jsonl", ]
    output:  "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_predictions_MP.jsonl"
    conda: "transformers"
    script:
        "scripts/run_inference.py"
rule run_inference_PS_HR:
    input:
        checkpoint = "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}/",
        datafiles = ["../data_PS-HR.jsonl", ]
    output:  "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_predictions_PS_HR.jsonl"
    conda: "transformers"
    script:
        "scripts/run_inference.py"
rule run_inference_PS_RS:
    input:
        checkpoint = "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}/",
        datafiles = ["../data_PS-RS.jsonl", ]
    output:  "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_predictions_PS_RS.jsonl"
    conda: "transformers"
    script:
        "scripts/run_inference.py"
rule run_inference_SLO:
    input:
        checkpoint = "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}/",
        datafiles = ["../data_SLO.jsonl"]
    output:  "models/model_{instances}_{steps}_{serial}/checkpoint-{steps}_predictions_SLO.jsonl"
    conda: "transformers"
    script:
        "scripts/run_inference.py"
rule gather_models:
#echo "gpu?"; read core; export CUDA_VISIBLE_DEVICES=$core; echo "batch?";  read batch; snakemake -j 2  --use-conda gather_models --batch gather_models="$batch"
    input:
        expand("models/model_{instances}_{steps}_{serial}/checkpoint-{steps}/",
        instances=INSTANCES,
        serial=model_serials,
        steps = STEPS,
        )+ expand("models/model_{instances}_{steps}_{serial}/checkpoint-{steps}/",
        instances=[10442],
        serial=[i for i in range(10)],
        steps = [6540],)
rule train_one:
    input:
        data = "../data_PS-HR.jsonl"
    output: directory("models/model_{instances}_{steps}_{serial}/checkpoint-{steps}/")
    conda:
        "transformers"
    script:
        "scripts/train_model.py"